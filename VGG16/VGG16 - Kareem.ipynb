{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications import VGG16;\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "IMG_WIDTH = 32\n",
    "IMG_HEIGHT = 32\n",
    "IMG_DEPTH = 1\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_train)\n",
    "num_classes = len(classes)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 784)\n",
    "x_test= x_test.reshape (-1, 784)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.dstack([x_train] * 3)\n",
    "x_test = np.dstack([x_test] * 3)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_test= x_test.reshape (-1, 28, 28, 1)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the images to 48 * 48 as required by VGG16\n",
    "x_train = np.asarray([img_to_array(array_to_img(im, scale=False).resize((32, 32))) for im in x_train])\n",
    "x_test = np.asarray([img_to_array(array_to_img(im, scale=False).resize((32, 32))) for im in x_test])\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the data and change data type\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, train_label, valid_label = train_test_split(x_train, y_train_one_hot, test_size=0.2, random_state=13)\n",
    "x_train.shape, x_valid.shape, train_label.shape, valid_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the input \n",
    "x_train = preprocess_input(x_train)\n",
    "x_valid = preprocess_input(x_valid)\n",
    "x_test  = preprocess_input (x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create base model of VGG16\n",
    "conv_base = VGG16(weights='vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH))\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features\n",
    "train_features = conv_base.predict(np.array(x_train), batch_size=BATCH_SIZE, verbose=1)\n",
    "test_features = conv_base.predict(np.array(x_test), batch_size=BATCH_SIZE, verbose=1)\n",
    "val_features = conv_base.predict(np.array(x_valid), batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the features so that they can be used for future\n",
    "np.savez(\"train_features\", train_features, train_label)\n",
    "np.savez(\"test_features\", test_features, y_test)\n",
    "np.savez(\"val_features\", val_features, valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Current shape of features\n",
    "print(train_features.shape, \"\\n\",  test_features.shape, \"\\n\", val_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten extracted features\n",
    "train_features_flat = np.reshape(train_features, (48000, 1 * 1 * 512))\n",
    "test_features_flat = np.reshape(test_features, (10000, 1 * 1 * 512))\n",
    "val_features_flat = np.reshape(val_features, (12000, 1 * 1 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_TRAIN_SAMPLES = train_features_flat.shape[0]\n",
    "NB_VALIDATION_SAMPLES = val_features_flat.shape[0]\n",
    "NB_EPOCHS = 100\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_dim=(1*1*512)))\n",
    "model.add(layers.LeakyReLU(alpha=0.1))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_learning = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    epsilon=0.0001,\n",
    "    cooldown=2,\n",
    "    min_lr=0)\n",
    "\n",
    "eary_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=7,\n",
    "    verbose=1,\n",
    "    mode='auto')\n",
    "\n",
    "callbacks = [reduce_learning, eary_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_features_flat,\n",
    "    train_label,\n",
    "    epochs=NB_EPOCHS,\n",
    "    validation_data=(val_features_flat, valid_label),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.plot(epochs, acc, 'red', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'blue', label='Validation acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Training and validation loss')\n",
    "plt.plot(epochs, loss, 'red', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'blue', label='Validation loss')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
